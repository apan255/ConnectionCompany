
/*
 * WordCountJob.java
 *
 * Created on Oct 22, 2012, 5:27:45 PM
 */

package org.sample;


import org.apache.hadoop.fs.Path;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

/**
 *
 * @author mac
 */
public class CompanyConnection {

	public static void initFirstJob(Job job) {
	     org.apache.hadoop.conf.Configuration conf = job.getConfiguration();
	// Generating code using Karmasphere Protocol for Hadoop 0.20
	// CG_GLOBAL

	// CG_INPUT_HIDDEN
	job.setInputFormatClass(org.apache.hadoop.mapreduce.lib.input.TextInputFormat.class);

	// CG_MAPPER_HIDDEN
=-	job.setMapperClass(org.sample.CompanyConnectionFirstMapper.class);
	job.getConfiguration().set("mapred.mapper.new-api", "true");

	// CG_MAPPER
	job.getConfiguration().set("mapred.map.tasks", "3");
	job.setMapOutputKeyClass(org.apache.hadoop.io.Text.class);
	job.setMapOutputValueClass(org.apache.hadoop.io.LongWritable.class);

	// CG_PARTITIONER_HIDDEN
	job.setPartitionerClass(org.apache.hadoop.mapreduce.lib.partition.HashPartitioner.class);

	// CG_PARTITIONER

	// CG_COMPARATOR_HIDDEN

	// CG_COMPARATOR

	// CG_COMBINER_HIDDEN

	// CG_REDUCER_HIDDEN
	job.setReducerClass(org.sample.CompanyConnectionFirstReducer.class);
	job.getConfiguration().set("mapred.reducer.new-api", "true");

	// CG_REDUCER
	job.getConfiguration().set("mapred.reduce.tasks", "2");
	job.setOutputKeyClass(org.apache.hadoop.io.Text.class);
	job.setOutputValueClass(org.apache.hadoop.io.LongWritable.class);

	// CG_OUTPUT_HIDDEN
	job.setOutputFormatClass(org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.class);

	// CG_OUTPUT

	// Others
	job.getConfiguration().set("", "");
	}

	
	
	
	public static void initSecondJob(Job job) {
	     org.apache.hadoop.conf.Configuration conf = job.getConfiguration();
	// Generating code using Karmasphere Protocol for Hadoop 0.20
	// CG_GLOBAL

	// CG_INPUT_HIDDEN
	job.setInputFormatClass(org.apache.hadoop.mapreduce.lib.input.KeyValueTextInputFormat.class);

	// CG_MAPPER_HIDDEN
	job.setMapperClass(org.sample.CompanyConnectionSecondMapper.class);
	job.getConfiguration().set("mapred.mapper.new-api", "true");

	// CG_MAPPER
	job.getConfiguration().set("mapred.map.tasks", "3");
	job.setMapOutputKeyClass(org.apache.hadoop.io.Text.class);
	job.setMapOutputValueClass(org.apache.hadoop.io.Text.class);

	// CG_PARTITIONER_HIDDEN
	job.setPartitionerClass(org.apache.hadoop.mapreduce.lib.partition.HashPartitioner.class);

	// CG_PARTITIONER

	// CG_COMPARATOR_HIDDEN

	// CG_COMPARATOR

	// CG_COMBINER_HIDDEN

	// CG_REDUCER_HIDDEN
	job.setReducerClass(org.sample.CompanyConnectionSecondReducer.class);
	job.getConfiguration().set("mapred.reducer.new-api", "true");

	// CG_REDUCER
	job.getConfiguration().set("mapred.reduce.tasks", "2");
	job.setOutputKeyClass(org.apache.hadoop.io.Text.class);
	job.setOutputValueClass(org.apache.hadoop.io.Text.class);

	// CG_OUTPUT_HIDDEN
	job.setOutputFormatClass(org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.class);

	// CG_OUTPUT

	// Others
	job.getConfiguration().set("", "");
	}
	
    public static void main(String[] args) throws Exception {
        Job job = new Job();

        /* Autogenerated initialization. */
        initFirstJob(job);

        /* Custom initialization. */
        initFirstCustom(job);

        /* Tell Task Tracker this is the main */
        job.setJarByClass(CompanyConnection.class);

        /* This is an example of how to set input and output. */
        FileInputFormat.setInputPaths(job, "dataInputFirstJOB//input.txt");
        FileOutputFormat.setOutputPath(job, new Path("dataOutputFirstJOB//output.txt"));
       // dataOutputSecondJOB
        /* You can now do any other job customization. */
        // job.setXxx(...);

        /* And finally, we submit the job. */
        job.submit();

        job.waitForCompletion(true);
        
    	System.out.println("*****************************gerrrrrreer******************************************= "  );

        
        Job job2 = new Job();

        /* Autogenerated initialization. */
        initSecondJob(job2);

        /* Custom initialization. */
       // initFirstCustom(job2);

        /* Tell Task Tracker this is the main */
        job2.setJarByClass(CompanyConnection.class);

        /* This is an example of how to set input and output. */
        FileInputFormat.setInputPaths(job2, "dataOutputFirstJOB//output.txt");
        FileOutputFormat.setOutputPath(job2, new Path("dataOutputSecondJOB//output.txt"));
       // dataOutputSecondJOB
        /* You can now do any other job customization. */
        // job.setXxx(...);

        /* And finally, we submit the job. */
        job2.submit();

        job2.waitForCompletion(true);
    }

    /**
     * This method is executed by the workflow
     */
    public static void initFirstCustom(Job job) {
        // Add custom initialisation here, you may have to rebuild your project before
        // changes are reflected in the workflow.
    }

    

}
